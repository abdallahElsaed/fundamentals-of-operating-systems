

* Every system has limited resources (like CPU and memory), and these need to be managed carefully. The operating system is responsible for managing these resources.
* The kernel itself can run without all the extra software
* The kernel handles the important tasks like running programs and interacting with hardware.
    - What is difference between OS and kernel ?
        - The OS is more than just the kernel; it includes tools to make the system easier to use.
        1. Kernel:
            - The kernel is the core part of the OS.
            - It is responsible for managing the system's resources (such as CPU, memory, and devices) and ensuring that multiple programs can run simultaneously without interfering with each other.
            - The kernel operates at a low level, interacting directly with the hardware.
            - It handles tasks like process management, memory management, device management (through drivers), and system security.
            - The kernel runs continuously and is the first program loaded after the system boots.
        2. Operating System (OS):
            - The OS includes the kernel but also provides additional tools and services for usability.
            - Besides the kernel, the OS contains software like user interfaces (e.g., graphical user interfaces or command-line tools) and system utilities (e.g., file managers, text editors).
            - The OS acts as a bridge between the user and the hardware, providing a platform for running applications.
            * While the kernel is crucial for managing system resources, the OS provides the full environment that users interact with (like Ubuntu, Windows, or macOS).

* The CPU, which performs calculations and runs programs, is one of the critical resources managed by the kernel.
* Each core has its own cache (a fast type of memory) that keeping data close to the CPU in the cache speeds up processing.
* Different processors require different machine instructions, which impacts how software is compiled.

### Memory 
* Memory Access is Slow: Accessing memory (RAM) is relatively slow compared to the CPU's speed. Every time the CPU needs to fetch data from RAM, there's a delay.
* Registers (which are small storage spaces inside the CPU) are the fastest memory available to the CPU. They store data that the CPU needs to access immediately. These registers are much faster than RAM.
* Random" Access: RAM allows for data to be accessed non-sequentially, unlike older storage devices (e.g., magnetic tapes or disks), where you had to go through data in sequence to reach what you wanted. This "random" nature makes RAM faster and more flexible. (**RAM like array, Old disk like linked list**)
* Volatile Memory: RAM is volatile, meaning that all data is lost when the system loses power. This is why data is frequently stored on more permanent storage devices (like disks).
* Processes (running programs) live entirely in RAM. Their **code** and **data** are loaded into memory when they run, and the CPU fetches and executes the code from memory.

### Hard derive and SSD 
* RAM is fast but volatile (data is lost when power is cut). So, eventually, data must be stored on persistent storage like hard drives or SSDs if you want it to survive after the process ends or the machine shuts down.
* **Controllers and APIs:** 
    * **Controllers**
        - Controllers are hardware components or circuits within storage devices (like SSDs) that manage the device's internal operations, such as reading, writing, and erasing data.
        - In older systems, these controllers weren’t built into the storage devices themselves; instead, the host system (like the computer’s CPU or OS) had to control everything. This created performance issues because the operating system had to be constantly updated to handle changes in the storage devices.
        - Modern SSDs have built-in controllers, which means that the SSD **itself manages many of its tasks**. This allows the SSD to perform better, and developers of these devices (e.g., hardware manufacturers) can innovate and improve the SSDs without needing the operating system to change.
    * **APIs (Application Programming Interfaces)**
        - An API is a **set of functions or protocols** that allow different pieces of software to communicate with each other. In this context, **the OS uses an API to interact with the SSD**.
        - Instead of directly interacting with the hardware (like the SSD controller), the OS or applications communicate through an API. This is important because it abstracts away the complexity of the hardware, making it easier for developers to use the SSD without needing to know how it works internally.
        - This abstraction allows the storage device (SSD) to evolve (with faster components, new designs, etc.), while the way software communicates with it remains the same through the API.